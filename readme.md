Browser (Chrome Extension)
â†“
Content Capture (Text / Prompt)
â†“
Backend API (app.py)
â†“
Base LLM (Gemini API)
â†“
4-Layer Safety Evaluation
â†“
Filtered / Blocked Response
â†“
Shown to User


---

## ğŸ” Safety Design (Core Innovation)

All medical content passes through **four safety layers**:

1. **Rule-Based Filters**
   - Detects dosage instructions
   - Detects diagnosis and treatment claims
   - Flags actionable medical advice

2. **Medical Risk Classification**
   - Identifies high-risk vs low-risk content
   - Detects emergency or clinical scenarios

3. **Evidence Validation**
   - Flags unsupported or false medical claims
   - Prevents hallucinated medical facts

4. **Final Decision Engine**
   - Decides: Allow / Warn / Block
   - Generates user-safe explanations

âš ï¸ **The user NEVER sees raw AI output**

---

## ğŸ“ Project Structure



safeai/
â”‚
â”œâ”€â”€ safeguard-health-backend/
â”‚ â”œâ”€â”€ app.py # Backend API server
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â”œâ”€â”€ .env # API keys (not committed)
â”‚ â”œâ”€â”€ test_api.py # API tests
â”‚ â””â”€â”€ venv/ # Virtual environment
â”‚
â”œâ”€â”€ safeguard-health-extension/
â”‚ â”œâ”€â”€ manifest.json # Chrome extension config
â”‚ â”œâ”€â”€ popup.html # Extension popup UI
â”‚ â”œâ”€â”€ popup.js
â”‚ â”œâ”€â”€ content.js # Webpage text capture
â”‚ â”œâ”€â”€ background.js
â”‚ â”œâ”€â”€ sidepanel.html # Protected AI chat UI
â”‚ â”œâ”€â”€ sidepanel.js
â”‚ â”œâ”€â”€ sidepanel.css
â”‚ â””â”€â”€ icons/
â”‚
â””â”€â”€ README.md


---

## ğŸš€ How to Run the Project (Local Setup)

### Step 1: Start the Backend

```bash
cd safeguard-health-backend
python app.py


Expected output:

ğŸ›¡ï¸ SAFEGUARD-Health Backend running on port 3000
ğŸ“Š Health check: http://localhost:3000/health
ğŸ’¬ Chat endpoint: http://localhost:3000/api/chat


âš ï¸ The backend must be running before using the extension.

Step 2: Load the Chrome Extension

Open Google Chrome

Go to chrome://extensions

Enable Developer Mode

Click Load Unpacked

Select the folder:

safeguard-health-extension/


The extension will appear in the Chrome toolbar

ğŸ§ª How to Use
ğŸ”¹ Feature 1: Evaluate Web Content

Select text on any webpage

Click the SAFEGUARD extension icon

Click Evaluate Selected Text

View safety analysis overlay on the page

ğŸ”¹ Feature 2: Protected AI Chat

Click the SAFEGUARD extension icon

Click ğŸ’¬ Chat with Protected AI

A side panel opens

Ask a medical question

AI generates â†’ SAFEGUARD filters â†’ Safe result shown

Example
User: How much aspirin should I take?
AI (raw): Take 500mg twice daily
SAFEGUARD: âŒ BLOCKED
User sees: "This response was blocked due to unsafe medical dosage advice."

ğŸ’¾ Data & Privacy

âŒ No database

âŒ No permanent storage

âœ… Chat history exists only during the session

âœ… When the side panel closes, all messages are cleared

ğŸ§  Technologies Used

Python (Backend API)

Google Gemini API (Base LLM)

Chrome Extension (Manifest V3)

JavaScript, HTML, CSS

Rule-based + LLM-based safety logic

ğŸ¯ Project Goals

Prevent unsafe medical AI outputs

Demonstrate responsible AI deployment

Act as a safety governor, not a medical assistant

Suitable for real-world clinical AI pipelines

âš ï¸ Disclaimer

SAFEGUARD-Health does not provide medical advice.
It is a safety evaluation system designed to reduce risks from AI-generated medical content.
Thank you for reviewing our project.
We appreciate your time, attention, and valuable consideration of SAFEGUARD-Health.
Your feedback and insights mean a lot to us and help us move closer to building safer, more responsible AI systems in healthcare.